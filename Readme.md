# ğŸ›°ï¸ SMAI Project Phase-2 â€“ Image-Based Geo-Localization

**Course:** Statistical Methods in Artificial Intelligence (SMAI)   

---

## ğŸŒ Overview

This project focuses on **predicting geographic and orientation attributes** from campus images.  
Each input image is used to predict four key values:

- **Latitude (scaled)**
- **Longitude (scaled)**
- **Angle** (camera orientation in degrees)
- **Region ID** (integer 1â€“15)

The models are trained and validated on labeled subsets, and evaluated using:
- **MSE** â†’ Latitude, Longitude, and Angle  
- **Accuracy** â†’ Region ID  

---

## ğŸ§  Methodology

Separate deep-learning models were designed for each prediction task using **PyTorch**.  
A range of state-of-the-art CNN and transformer architectures were explored and fine-tuned, including:

- **ConvNeXt-Tiny / Base**
- **Vision Transformer (ViT-B/16)**
- **EfficientNet-B0**
- **ResNet-18 / ResNet-50**

All experiments were conducted with reproducible seeds, standardized augmentations, and adaptive learning-rate schedulers.

---

### 1ï¸âƒ£ Latitude & Longitude Prediction
- **Type:** Regression  
- **Architecture:** ViT-B/16 & ConvNeXt  
- **Loss Function:** Mean Squared Error (MSE)  
- **Optimizer:** Adam (`lr = 0.001`)  
- **Scaling:** Latitude & longitude were normalized for stable training  
- **Validation MSE:** â‰ˆ **1.16 Ã— 10â¶ (averaged)**  

---

### 2ï¸âƒ£ Angle Prediction
- **Type:** Circular Regression  
- **Architecture:** ResNet-18 / ConvNeXt-Tiny  
- **Loss Function:** Custom `AngularLoss`  
  (wraps angular values within 0â€“360Â° and minimizes circular distance)  
- **Metric:** Mean Angular Error (MAE)  
- **Validation MAE:** â‰ˆ **0.0246** (â‰ˆ **8.9Â°**)  

---

### 3ï¸âƒ£ Region ID Classification
- **Type:** Multi-class Classification (15 classes)  
- **Architecture:** EfficientNet-B0 (pretrained on ImageNet)  
- **Loss Function:** Cross-Entropy with Label Smoothing (0.1)  
- **Metric:** Accuracy  
- **Validation Accuracy:** â‰ˆ **94.85%**

---

## âš™ï¸ Training Setup

- **Framework:** PyTorch  
- **Batch Size:** 32  
- **Epochs:** 50
- **Optimizer:** Adam / AdamW  
- **Scheduler:** ReduceLROnPlateau  
- **Hardware:** NVIDIA GPU (CUDA)  
- **Seed:** 42 (for full reproducibility)  

---

## ğŸ“ Repository Structure

```

SMAI_Project/
â”œâ”€â”€ latitude_longitude/
â”‚   â”œâ”€â”€ train_latlon_vit_convnext.py
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ angle/
â”‚   â”œâ”€â”€ angle_prediction_resnet.py
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ region/
â”‚   â”œâ”€â”€ region_classifier_efficientnet.py
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ images_train/
â”‚   â”œâ”€â”€ images_val/
â”‚   â”œâ”€â”€ labels_train.csv
â”‚   â”œâ”€â”€ labels_val.csv
â””â”€â”€ README.md

```

---

## ğŸ§© Results Summary

| Task | Model | Metric | Validation Score |
|------|--------|---------|------------------|
| Latitude | ConvNeXt | MSE | ~1.16Ã—10â¶ |
| Longitude | ViT-B/16 | MSE | ~1.16Ã—10â¶ |
| Angle | ResNet-18 | MAE | 0.0246 (~8.9Â°) |
| Region ID | EfficientNet-B0 | Accuracy | 94.85% |

---

## ğŸš€ Future Work

- Multi-task unified model for joint learning of all four outputs  
- Use **Swin Transformer** or **ConvNeXt-V2** for improved spatial sensitivity  
- Incorporate attention-based regularization  

---
