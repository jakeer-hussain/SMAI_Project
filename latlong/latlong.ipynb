{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11669217,"sourceType":"datasetVersion","datasetId":7323323},{"sourceId":11669761,"sourceType":"datasetVersion","datasetId":7323640},{"sourceId":11669785,"sourceType":"datasetVersion","datasetId":7323654},{"sourceId":11669791,"sourceType":"datasetVersion","datasetId":7323659}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"ffa941cf","cell_type":"code","source":"import os\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom torchvision.models import convnext_tiny, ConvNeXt_Tiny_Weights\nfrom PIL import Image\nimport csv\nimport random\nimport numpy as np\n","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true},"outputs":[],"execution_count":null},{"id":"2f7c4032","cell_type":"code","source":"seed = 42\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true},"outputs":[],"execution_count":null},{"id":"7c9227c9","cell_type":"code","source":"def remove_outliers_quantile(df, column_names, low_q=0.01, high_q=0.99):\n    for col in column_names:\n        low, high = df[col].quantile([low_q, high_q])\n        df = df[(df[col] >= low) & (df[col] <= high)]\n    return df.reset_index(drop=True)\n\n# === Dataset Class ===\nclass LocationDataset(Dataset):\n    def __init__(self, csv_file, image_dir, transform=None, filter_outliers=False):\n        df = pd.read_csv(csv_file)\n\n        if filter_outliers:\n            df = remove_outliers_quantile(df, ['latitude', 'longitude'])\n\n        self.data = df.reset_index(drop=True)\n        self.image_dir = image_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        row = self.data.iloc[idx]\n        image_path = os.path.join(self.image_dir, row['filename'])\n\n        image = Image.open(image_path).convert('RGB')\n        if self.transform:\n            image = self.transform(image)\n\n        target = torch.tensor([row['latitude'], row['longitude']], dtype=torch.float32)\n        return image, target\n","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true},"outputs":[],"execution_count":null},{"id":"1d6f1b8e","cell_type":"code","source":"def compute_mean_std(dataset):\n    loader = DataLoader(dataset, batch_size=64, shuffle=False)\n    mean, std, n_samples = 0.0, 0.0, 0\n    for imgs, _ in loader:\n        batch = imgs.size(0)\n        imgs = imgs.view(batch, imgs.size(1), -1)\n        mean += imgs.mean(2).sum(0)\n        std += imgs.std(2).sum(0)\n        n_samples += batch\n    return (mean / n_samples).tolist(), (std / n_samples).tolist()\n\n# === Training Function ===\ndef train_one_epoch(model, loader, criterion, optimizer, device):\n    model.train()\n    total_loss = 0.0\n    for imgs, targets in loader:\n        imgs, targets = imgs.to(device), targets.to(device)\n        preds = model(imgs)\n        loss = criterion(preds, targets)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    return total_loss / len(loader)\n","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true},"outputs":[],"execution_count":null},{"id":"fd785635","cell_type":"code","source":"def train_one_epoch(model, loader, criterion, optimizer, device):\n    model.train()\n    total_loss = 0.0\n    for imgs, targets in loader:\n        imgs, targets = imgs.to(device), targets.to(device)\n        preds = model(imgs)\n        loss = criterion(preds, targets)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    return total_loss / len(loader)\n\n# === Validation Function (with exclusion) ===\ndef validate(model, loader, criterion, device, exclude_indices):\n    model.eval()\n    total_loss, current_index = 0.0, 0\n    with torch.no_grad():\n        for imgs, targets in loader:\n            batch_size = imgs.size(0)\n            imgs, targets = imgs.to(device), targets.to(device)\n            preds = model(imgs)\n\n            for i in range(batch_size):\n                if current_index + i in exclude_indices:\n                    preds[i] = targets[i] = torch.tensor([0.0, 0.0], device=device)\n\n            total_loss += criterion(preds, targets).item()\n            current_index += batch_size\n    return total_loss / len(loader)\n","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true},"outputs":[],"execution_count":null},{"id":"8c94a75e","cell_type":"code","source":"def save_predictions(model, loader, device, exclude_indices, output_file='Latlong_predictions.csv', total_samples=738):\n    # === Save Predictions ===\n# === Save Predictions ===\n    predictions = []\n    exclude_indices = set([95, 145, 146, 158, 159, 160, 161])\n    global_idx = 0  # Track global index across validation dataset\n\n    model.eval()\n    with torch.no_grad():\n        for imgs, _ in val_loader:\n            imgs = imgs.to(device)\n            preds = model(imgs)\n\n            for i in range(len(preds)):\n                if global_idx in exclude_indices:\n                    lat, lon = 0, 0\n                else:\n                    lat = round(preds[i][0].item())\n                    lon = round(preds[i][1].item())\n                predictions.append([global_idx, lat, lon])\n                global_idx += 1\n\n    # Fill any remaining rows up to 738 (if required)\n    for i in range(global_idx, 738):\n        predictions.append([i, 0, 0])\n\n    # Write to CSV\n    with open('Latlong_predictions.csv', mode='w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(['id', 'Latitude', 'Longitude'])\n        writer.writerows(predictions)\n\n    print(\"Predictions (with excluded IDs marked as 0,0) saved to 'Latlong_predictions.csv'\")\n\n","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true},"outputs":[],"execution_count":null},{"id":"bb2cba52","cell_type":"code","source":"if __name__ == \"__main__\":\n    # Pre-transform to calculate mean/std\n    pre_transform = transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor()])\n    tmp_dataset = LocationDataset('/kaggle/input/csv-files/labels_train.csv', '/kaggle/input/images-train/images_train', transform=pre_transform, filter_outliers=True)\n    mean, std = compute_mean_std(tmp_dataset)\n    print(f\"Computed Mean: {mean}, Std: {std}\")\n    \n    # Final transforms\n    train_transform = transforms.Compose([\n        transforms.Resize((256, 256)),  # Resize all images to 256x256\n        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # Random crop of the image and resize to 224x224\n        transforms.RandomHorizontalFlip(),  # Flip images horizontally with 50% probability\n        transforms.RandomRotation(30),  # Random rotation between -30 and +30 degrees\n        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),  # Random color adjustments\n        transforms.ToTensor(),  # Convert the image to a Tensor\n        transforms.Normalize(mean=mean, std=std)  # Normalize the image with the computed mean and std\n    ])\n    \n    # Transforms for Validation (No Augmentation)\n    val_transform = transforms.Compose([\n        transforms.Resize((256, 256)),  # Resize all images to 256x256\n        transforms.ToTensor(),  # Convert the image to a Tensor\n        transforms.Normalize(mean=mean, std=std)  # Normalize the image with the computed mean and std\n    ])\n\n    # Datasets & Loaders\n    train_dataset = LocationDataset('/kaggle/input/csv-files/labels_train.csv', '/kaggle/input/images-val/images_val', transform=train_transform, filter_outliers=True)\n    val_dataset = LocationDataset('/kaggle/input/csv-files/labels_train.csv', '/kaggle/input/images-val/images_val', transform=val_transform)\n    train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=20)\n\n    # Model Setup\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    weights = ConvNeXt_Tiny_Weights.DEFAULT\n    model = convnext_tiny(weights=weights)\n    model.classifier[2] = nn.Linear(model.classifier[2].in_features, 2)\n    model = model.to(device)\n\n    # Training Setup\n    criterion = nn.MSELoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=1e-4)\n\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.1, verbose=True)\n\n    exclude_indices = set([95, 145, 146, 158, 159, 160, 161])\n\n    best_val_loss = float('inf')  # Initialize with a large value\n    best_model_wts = None\n\n    # Train Loop\n    for epoch in range(1):\n        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n        val_loss = validate(model, val_loader, criterion, device, exclude_indices)\n        print(f\"Epoch {epoch+1} | Train MSE Loss: {train_loss:.4f} | Val MSE Loss: {val_loss:.4f}\")\n\n        scheduler.step(val_loss)\n\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            best_model_wts = model.state_dict()  # Save the model's state (weights)\n            print(f\"Validation loss improved, saving model...\")\n            torch.save(best_model_wts, 'latlong.pth')\n    # Save predictions\n    save_predictions(model, val_loader, device, exclude_indices)\n","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true},"outputs":[],"execution_count":null}]}